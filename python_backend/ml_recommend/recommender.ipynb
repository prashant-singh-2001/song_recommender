{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3662,"status":"ok","timestamp":1712130252350,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"lqQbg0IDxU6D","outputId":"a45a3f59-a837-4bd8-e86f-3f28056fbbe1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd  # Import the pandas library for data manipulation (working with DataFrames and Series)\n","\n","import numpy as np  # Import the numpy library for numerical computations (arrays, matrices, etc.)\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer from scikit-learn for creating TF-IDF vector representations of text data\n","\n","from sklearn.metrics.pairwise import cosine_similarity  # Import cosine_similarity function from scikit-learn for calculating similarity between vectors\n","\n","import nltk  # Import the Natural Language Toolkit (NLTK) library for text processing tasks\n","\n","from nltk.stem.porter import PorterStemmer  # Import PorterStemmer class from NLTK for stemming words (reducing them to their base form)\n","\n","import pickle  # Import the pickle library for saving and loading Python objects\n","\n","import requests  # Import the requests library for making HTTP requests (potentially for fetching song data)\n","\n","from google.colab import drive  # Import functionality from Google Colab to mount your Google Drive\n","\n","drive.mount('/content/drive')  # Mount your Google Drive to access data stored there (assuming you're using Google Colab)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1712130254645,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"t8PN2a3LxU6J"},"outputs":[],"source":["# Read data from CSV file\n","df = pd.read_csv('spotify_millsongdata.csv')\n","\n","# Drop the 'link' column (assuming it's not relevant for recommendations)\n","df.drop('link', axis=1, inplace=True)\n","\n","# Preprocess the 'text' column for better vectorization:\n","#   - Lowercase all characters\n","#   - Replace word boundaries with a single space\n","#   - Replace newlines with spaces (assuming each line represents a sentence or phrase)\n","df['text'] = df['text'].str.lower().replace(r'\\w\\s', ' ').replace(r'\\n', ' ', regex=True)\n","\n","# Sample 20,000 rows from the DataFrame (potentially for efficiency or memory limitations)\n","df = df.sample(20000).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712130254645,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"b6HSnCzExU6L"},"outputs":[],"source":["# Tokenization function\n","stemmer = PorterStemmer()  # Create a PorterStemmer object for stemming words\n","\n","def tokenization(text):\n","    \"\"\"\n","    This function performs tokenization and stemming on a given text string.\n","\n","    Args:\n","        text (str): The text string to be processed.\n","\n","    Returns:\n","        str: The preprocessed text with tokens stemmed and joined back into a string.\n","    \"\"\"\n","\n","    # Tokenize the text into words using NLTK's word_tokenize\n","    tokens = nltk.word_tokenize(text)\n","\n","    # Apply stemming to each token using the PorterStemmer\n","    stemming = [stemmer.stem(w) for w in tokens]\n","\n","    # Join the stemmed tokens back into a single string with spaces\n","    return \" \".join(stemming)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":103608,"status":"ok","timestamp":1712130358251,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"cvmk2Ri3xU6N"},"outputs":[],"source":["# Apply tokenization\n","df['text'] = df['text'].apply(tokenization)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2979,"status":"ok","timestamp":1712130361216,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"QccJrUhCxU6N"},"outputs":[],"source":["# TF-IDF Vectorization\n","tfidf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n","matrix = tfidf_vectorizer.fit_transform(df['text'])"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":26019,"status":"ok","timestamp":1712130387232,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"_FNOok7PztZ2"},"outputs":[],"source":["# Compute cosine similarity\n","similarity = cosine_similarity(matrix)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1712130387232,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"3hxlIVaOxU6O"},"outputs":[],"source":["# Recommendation function\n","def recommendation(song_df):\n","    idx = df[df['song'] == song_df].index[0]\n","    distances = sorted(list(enumerate(similarity[idx])), reverse=True, key=lambda x: x[1])\n","\n","    songs = []\n","    for m_id in distances[1:21]:\n","        songs.append(df.iloc[m_id[0]]['song'])\n","\n","    return songs# Recommendation function"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":41159,"status":"ok","timestamp":1712130428387,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"5DS74-o-xU6P"},"outputs":[],"source":["# Create an empty dictionary to store similarity information\n","similarity_dict = {}\n","\n","# Iterate through each row (song) in the DataFrame\n","for i, row in df.iterrows():\n","    \"\"\"\n","    This loop calculates and stores similarity information for each song.\n","\n","    Args:\n","        i (int): The index of the current row (song) being processed.\n","        row (pandas.Series): A single row (song) from the DataFrame.\n","    \"\"\"\n","\n","    # Get cosine similarity vector for the current song (row)\n","    similarity = cosine_similarity(df.loc[i, 'text'].reshape(1, -1), df['text'])[0]\n","\n","    # Sort similarity indices in descending order (most similar first) and exclude the current song itself (index 0)\n","    sim_indices = np.argsort(similarity)[::-1][1:21]\n","\n","    # Get corresponding cosine similarity scores for the top 20 similar songs\n","    sim_scores = [similarity[j] for j in sim_indices]\n","\n","    # Create a list of tuples (index, similarity score) for top 20 similar songs\n","    similar_songs = list(zip(sim_indices, sim_scores))\n","\n","    # Store the list of similar songs (tuples) in the dictionary with the current song as the key\n","    similarity_dict[row['song']] = similar_songs\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1712130428387,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"-Mnjq0xexU6R","outputId":"85eb1e06-57ca-40b9-d730-e740f3c60341"},"outputs":[{"data":{"text/plain":["array([1.        , 0.00418043, 0.        , ..., 0.00363018, 0.00104286,\n","       0.01859492])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["similarity[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_album_cover(artist_name, song_name, api_key=\"YOUR_LAST_FM_API_KEY\"):\n","    \"\"\"\n","    Fetches album cover URL for a given song using Last.fm API.\n","\n","    Args:\n","        artist_name (str): Name of the artist.\n","        song_name (str): Title of the song.\n","        api_key (str, optional): Your Last.fm API key. Defaults to \"YOUR_LAST_FM_API_KEY\".\n","\n","    Returns:\n","        str: URL of the album cover image (if found), or error message otherwise.\n","    \"\"\"\n","\n","    url = f\"https://ws.audioscrobbler.com/2.0/?method=track.getInfo&api_key={api_key}&artist={artist_name}&track={song_name}&format=json\"\n","    response = requests.get(url)\n","\n","    if response.status_code == 200:\n","        try:\n","            data = response.json()\n","            if 'track' in data and 'album' in data['track'] and 'image' in data['track']['album']:\n","                # Select the largest image URL from the Last.fm response\n","                album_cover_url = data['track']['album']['image'][-1]['#text']\n","                print(album_cover_url)\n","                return album_cover_url\n","            else:\n","                print(\"Album cover not found.\")\n","                return \"Album cover not found.\"\n","        except Exception as e:\n","            print(f\"Error parsing JSON: {e}\")\n","            return \"Error parsing JSON.\"\n","    else:\n","        print(f\"Error retrieving data from Last.fm API. Status code: {response.status_code}\")\n","        return \"Error retrieving data from Last.fm API.\"\n","\n","# Replace 'YOUR_LAST_FM_API_KEY' with your actual Last.fm API key\n","api_key = \"YOUR_LAST_FM_API_KEY\"\n","\n","# Add a new column 'img_url' to the DataFrame containing album cover URLs\n","df['img_url'] = df.apply(lambda row: get_album_cover(row['artist'], row['song'], api_key), axis=1)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2477,"status":"ok","timestamp":1712130430861,"user":{"displayName":"Prashant Singh","userId":"05832982415237409390"},"user_tz":-330},"id":"IloSoWLgxU6S"},"outputs":[],"source":["# Save similarity dictionary\n","with open('similarity_dict.pkl', 'wb') as file:\n","    pickle.dump(similarity_dict, file)\n","\n","# Save dataframe\n","with open('data.pkl', 'wb') as file:\n","    pickle.dump(df, file)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
